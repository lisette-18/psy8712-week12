---
title: "psy 8712- week 12"
author: "Lisette Horne"
date: "2024-04-18"
output: html_document
---
#Script Settings and Resources
```{r setup, include=FALSE}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(tidyverse)
library(tidytext)
library(wordcloud)
library(topicmodels)
library(tm)
library(RedditExtractoR)
library(ldatuning)
library(dendextend)
library(qdap)
library(textstem)
library(RWeka)
```

#Data Import
```{r}
#reddit_thread_urls <- find_thread_urls(
  #subreddit = "IOPsychology",
  #sort_by = "new",
  #period = "year") %>%
  #mutate(date_utc = ymd(date_utc))

#thread_urls2 <- filter(reddit_thread_urls, timestamp > as.numeric(as.POSIXct(Sys.Date() - 365)))

#reddit_urls <- reddit_thread_urls$url

#reddit_content <- get_thread_content(reddit_urls)

#week12_tbl <- tibble(
  #title = reddit_content$threads$title,
  #upvotes = reddit_content$threads$upvotes)

#write out all files as csv
#write_csv(reddit_thread_urls, file = "../data/reddit_data.csv")
#write_csv(week12_tbl, "../data/week12_tbl.csv")
reddit_thread_urls <- read_csv("../data/reddit_data.csv", show_col_types = FALSE)
week12_tbl <- read_csv("../data/week12_tbl.csv", show_col_types = FALSE)
```

```{r}
io_corpus_original <- VCorpus(VectorSource(week12_tbl$title))

io_corpus <- io_corpus_original %>%
  tm_map(content_transformer(replace_abbreviation)) %>%
  tm_map(content_transformer(replace_contraction)) %>%
  tm_map(content_transformer(str_to_lower)) %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeWords, c("io psychology", "iopsy", "iopsych", "io psych", "iopsychology", "riopsychology", "organizational psychology", "industrial organizational psychology", "io", "i/o")) %>%
  tm_map(stripWhitespace)
```

```{r}
compare_them <- function(x,y) {
  casenum <- sample.int(length(x), 1)
  print(x$content[[casenum]]$content)
  print(y$content[[casenum]]$content)
}

compare_them(io_corpus_original, io_corpus)
```

```{r}
tokenizer <- function(x) NGramTokenizer(x, Weka_control(min=1, max=2))

io_dtm <-  DocumentTermMatrix(io_corpus, control = list(tokenize = tokenizer))


io_slim_dtm <- removeSparseTerms(io_dtm, 0.997)

io_dtm <- io_dtm %>%
  as.matrix %>%
  as_tibble
```


```{r}
library(ldatuning)
rowTotals <- apply(io_dtm[,2:328], 1, sum)
io_dtm_clean <- io_dtm[rowTotals> 0, ] 

dtm_tune <- FindTopicsNumber(
 io_dtm_clean , 
  topics = seq(2, 10, 1),
  metrics = c(
    "Griffiths2004",
    "CaoJuan2009",
    "Arun2010",
    "Deveaud2014"),
  verbose = T)

FindTopicsNumber(dtm_tune)

lda_results <- LDA(io_dtm_clean, 5)

lda_beta <- tidy(lda_results, matrix = "beta") %>%
  group_by(topic) %>%
  top_n(951, beta) %>%
  arrange(topic, -beta)

tidy(lda_results, matrix = "gamma") %>%
  group_by(document) %>%
  top_n(1, gamma) %>%
  slice(1) %>%
  ungroup %>%
  mutate(document = as.numeric(document)) %>%
  arrange(document) 

# Create topics_tbl tibble
topics_tbl <- tibble(tidy(lda_results, matrix = "gamma")) %>%
  group_by(document) %>%
  top_n(1, gamma) %>%
  rename(doc_id = document, probability = gamma) %>%
  mutate(doc_id = as.numeric(doc_id)) %>%
  arrange(doc_id) %>%
  mutate(original = week12_tbl$title[doc_id]) %>%
  select(doc_id, original, topic, probability)
``` 

#Question 1
##Using the beta matrix alone, the highest beta value is very low, which may suggest that the topic mapping is not strongm but based on the topics, I would think that topic 1 -  career, topic 2 = measurements, topic 3 =  readings, topic 4 = more career, topic 5 = graduate education
#Question 2
##Looking at the information, I do not think that the names derived from your interpretation of the beta matrix does not conceptullay match with the content of the original posts. This is a relfecttion of the content validity and the construct validity.

#Visualization
```{r}
library(wordcloud)
wordcloud(
  words = names(io_dtm),
  freq = colSums(io_dtm),
  max.words = 25,
  colors = brewer.pal(9, "Blues")
)
```




